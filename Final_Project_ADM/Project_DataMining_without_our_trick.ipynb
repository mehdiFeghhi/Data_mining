{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries:\n"
      ],
      "metadata": {
        "id": "Kp7Tderq1N-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEK4qpna01h8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the CIFAR10 dataset:\n"
      ],
      "metadata": {
        "id": "eWnqT-NC1Plt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "x1dEMW-l1BZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subset 0,1"
      ],
      "metadata": {
        "id": "HEYqhrO4mVHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "def create_subset(dataset, labels):\n",
        "    indices = [idx for idx, label in enumerate(dataset.targets) if label in labels]\n",
        "    subset = Subset(dataset, indices)\n",
        "    return subset\n"
      ],
      "metadata": {
        "id": "AYThW1ozlo7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "train_loader_2 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_2 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "6zIL9O-jloKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "train_loader_3 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_3 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "SIHSF2E4mpAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_4 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_4 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "l0ezpImtmuGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_5 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_5 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "KgQBRpFLmwZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_6 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_6 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "ZH2RVP7-mzV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_7 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_7 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "EbxSO_7dm3Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6,7]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_8 = DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_8 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "rmCmt5RVm_we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6,7,8]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_9= DataLoader(subset, batch_size=25, shuffle=True)\n",
        "\n",
        "test_subset = create_subset(test_dataset, subset_labels)\n",
        "test_loader_9 = DataLoader(test_subset,batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GPEjajzNnFW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRIOOfOBh99u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "b3gs4pEo1mSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wnGbhpt1zRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pre-trained WideResNet model:\n"
      ],
      "metadata": {
        "id": "o3t9odvC1TZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Set the device to GPU\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Set the device to CPU\n",
        "    print(\"Using CPU\")"
      ],
      "metadata": {
        "id": "xw2d3aFZ194K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = torchvision.models.wide_resnet50_2(pretrained=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "7TFC1xKF1EZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the model by removing the output layer and keeping the features:\n"
      ],
      "metadata": {
        "id": "jox-COKu2WBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(*list(model.children())[:-1])\n"
      ],
      "metadata": {
        "id": "a31k-FUv1KDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new fully connected network for classification:\n"
      ],
      "metadata": {
        "id": "NUNYXpqs2Wx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the network class\n",
        "class SimpleNetwork(nn.Module):\n",
        "    def __init__(self, num_outputs):\n",
        "        super(SimpleNetwork, self).__init__()\n",
        "\n",
        "        self.input_layer = nn.Linear(2048, 64)\n",
        "        self.hidden_layer = nn.Linear(64, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(32, num_outputs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(self.input_layer.weight.device)  # Move input tensor to the same device as the parameters\n",
        "        x1 = self.input_layer(x)\n",
        "        x1_relu  = self.relu(x1)\n",
        "        x2  = self.hidden_layer(x1_relu)\n",
        "        x2_relu  = self.relu(x2)\n",
        "        x = self.output_layer(x2_relu)\n",
        "        x = self.sigmoid(x)\n",
        "        return x,x2_relu,x1_relu\n",
        "\n",
        "\n",
        "\n",
        "# Specify the number of outputs for the network\n",
        "# num_outputs = 10  # You can change this number based on your needs\n",
        "\n",
        "# # Create an instance of the network\n",
        "# network = SimpleNetwork(num_outputs)"
      ],
      "metadata": {
        "id": "L6a0RCMc2UI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this updated code, I modified the forward method of the NuSALoss class to include an additional input parameter inputs, which represents the input sample to each layer (xl).\n",
        "\n",
        "Within the loop that iterates over the named parameters of the model, xl is now set as the inputs passed to the forward method. The NuSA term is computed by performing the necessary matrix multiplications and norms between column_space_basis and xl.\n",
        "\n",
        "By including inputs as an argument and using it in the NuSA term calculation, the code now incorporates the input sample for each layer into the loss function, as specified in the equation you provided.\n",
        "\n",
        "Once again, I apologize for the confusion caused by the incorrect information in my previous response."
      ],
      "metadata": {
        "id": "kfC0IHDP3JE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n"
      ],
      "metadata": {
        "id": "RjT4lYUd3lAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "def train(train_loader,network):\n",
        "\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
        "    global loss_function\n",
        "\n",
        "\n",
        "    # new_train_loader = make_train_loader_from_number_class_we_want(number_of_known_classes)\n",
        "\n",
        "    for epoch in range(35):\n",
        "        print(epoch)\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through the WideResNet model\n",
        "            with torch.no_grad():\n",
        "                features = model(images)\n",
        "\n",
        "            # Flatten the features\n",
        "            features = features.view(features.size(0), -1)\n",
        "\n",
        "            # Forward pass through the classifier\n",
        "            outputs,relue_x2,relue_x1 = network(features)\n",
        "            inputs = [features,relue_x1,relue_x2]\n",
        "\n",
        "            # Move input and target tensors to the same device\n",
        "            # inputs = inputs.to(device)\n",
        "            outputs = outputs.to(device)\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'loss: {loss}')\n",
        "\n",
        "    return network"
      ],
      "metadata": {
        "id": "tv99XWM94IgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the classifier's performance:\n",
        "`"
      ],
      "metadata": {
        "id": "csQDdFUL8jyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def test(test_loader,network):\n",
        "\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for input, label in test_loader:\n",
        "\n",
        "        input = input.to(device)\n",
        "        label = label.to(device)\n",
        "        total += 1\n",
        "\n",
        "        features = model(input)\n",
        "\n",
        "        # Flatten the features\n",
        "        features = features.view(features.size(0), -1)\n",
        "\n",
        "\n",
        "        output,relue_x2,relu_x1 = network(features)  # Compute forward pass to get output for the sample\n",
        "        _, predicted = torch.max(output, 1)\n",
        "\n",
        "        if predicted.item() == label :\n",
        "            correct += 1\n",
        "\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hAMTLTwB8kbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "test_res = []\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/data_maining_project/test_res.pkl\"\n",
        "\n",
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n",
        "\n",
        "test_res = []"
      ],
      "metadata": {
        "id": "c3mxL98ipvOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an instance of the network for known 2\n",
        "network = SimpleNetwork(2)\n",
        "network = train(train_loader_2,network)\n",
        "res = test(test_loader_2,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "QhVPmDRsNLgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "sODu9nqd2Jdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an instance of the network for known 3\n",
        "network = SimpleNetwork(3)\n",
        "network = train(train_loader_3,network)\n",
        "res = test(test_loader_3,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "mgHewIPs2Pdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "UGhJ6Jqq2Whe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 4\n",
        "network = SimpleNetwork(4)\n",
        "network = train(train_loader_4,network)\n",
        "res = test(test_loader_4,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "mOZsBlar2XFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "ChwrvDiO2fT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 5\n",
        "network = SimpleNetwork(5)\n",
        "network = train(train_loader_5,network)\n",
        "res = test(test_loader_5,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "P4c4z2GO2mAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "fi4Dnkxc2vhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 6\n",
        "network = SimpleNetwork(6)\n",
        "network = train(train_loader_6,network)\n",
        "res = test(test_loader_6,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "yfD463_H2wOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "8t1B3_t_23JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 7\n",
        "network = SimpleNetwork(7)\n",
        "network = train(train_loader_7,network)\n",
        "res = test(test_loader_7,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "T5IxLikL24lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "f8BxB8V13APh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 8\n",
        "network = SimpleNetwork(8)\n",
        "network = train(train_loader_8,network)\n",
        "res = test(test_loader_8,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "nckzBZal3Ayt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "1bD-erDY3K2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 9\n",
        "network = SimpleNetwork(9)\n",
        "network = train(train_loader_9,network)\n",
        "res = test(test_loader_9,network)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "IcFWr8Jv3Lav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "JjS2sJBf3RDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/data_maining_project/test_res.pkl\"\n",
        "\n",
        "# Write the content to the file\n",
        "loaded_object = joblib.load(file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kJPmJyJe-IcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of labels for the x-axis\n",
        "labels = [i for i in range(2,10)]\n",
        "\n",
        "# Create the bar graph\n",
        "plt.bar(labels, loaded_object)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Bar Graph')\n",
        "\n",
        "# Display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FQgXiG8_Ckd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}