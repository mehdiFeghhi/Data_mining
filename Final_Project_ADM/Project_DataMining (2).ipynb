{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the necessary libraries:\n"
      ],
      "metadata": {
        "id": "Kp7Tderq1N-2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEK4qpna01h8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the CIFAR10 dataset:\n"
      ],
      "metadata": {
        "id": "eWnqT-NC1Plt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "x1dEMW-l1BZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Subset 0,1"
      ],
      "metadata": {
        "id": "HEYqhrO4mVHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "def create_subset(dataset, labels):\n",
        "    indices = [idx for idx, label in enumerate(dataset.targets) if label in labels]\n",
        "    subset = Subset(dataset, indices)\n",
        "    return subset\n"
      ],
      "metadata": {
        "id": "AYThW1ozlo7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "train_loader_2 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "6zIL9O-jloKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_3 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "SIHSF2E4mpAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_4 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "l0ezpImtmuGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_5 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "KgQBRpFLmwZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_6 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "ZH2RVP7-mzV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_7 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "EbxSO_7dm3Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6,7]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_8 = DataLoader(subset, batch_size=25, shuffle=True)\n"
      ],
      "metadata": {
        "id": "rmCmt5RVm_we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the labels for the subset\n",
        "subset_labels = [0, 1,2,3,4,5,6,7,8]\n",
        "# Create the subset\n",
        "subset = create_subset(train_dataset, subset_labels)\n",
        "\n",
        "train_loader_9= DataLoader(subset, batch_size=25, shuffle=True)"
      ],
      "metadata": {
        "id": "GPEjajzNnFW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iRIOOfOBh99u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "b3gs4pEo1mSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7wnGbhpt1zRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the pre-trained WideResNet model:\n"
      ],
      "metadata": {
        "id": "o3t9odvC1TZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Set the device to GPU\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")  # Set the device to CPU\n",
        "    print(\"Using CPU\")"
      ],
      "metadata": {
        "id": "xw2d3aFZ194K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = torchvision.models.wide_resnet50_2(pretrained=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "7TFC1xKF1EZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the model by removing the output layer and keeping the features:\n"
      ],
      "metadata": {
        "id": "jox-COKu2WBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(*list(model.children())[:-1])\n"
      ],
      "metadata": {
        "id": "a31k-FUv1KDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a new fully connected network for classification:\n"
      ],
      "metadata": {
        "id": "NUNYXpqs2Wx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the network class\n",
        "class SimpleNetwork(nn.Module):\n",
        "    def __init__(self, num_outputs):\n",
        "        super(SimpleNetwork, self).__init__()\n",
        "\n",
        "        self.input_layer = nn.Linear(2048, 64)\n",
        "        self.hidden_layer = nn.Linear(64, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.output_layer = nn.Linear(32, num_outputs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x.to(self.input_layer.weight.device)  # Move input tensor to the same device as the parameters\n",
        "        x1 = self.input_layer(x)\n",
        "        x1_relu  = self.relu(x1)\n",
        "        x2  = self.hidden_layer(x1_relu)\n",
        "        x2_relu  = self.relu(x2)\n",
        "        x = self.output_layer(x2_relu)\n",
        "        x = self.sigmoid(x)\n",
        "        return x,x2_relu,x1_relu\n",
        "\n",
        "\n",
        "\n",
        "# Specify the number of outputs for the network\n",
        "# num_outputs = 10  # You can change this number based on your needs\n",
        "\n",
        "# # Create an instance of the network\n",
        "# network = SimpleNetwork(num_outputs)"
      ],
      "metadata": {
        "id": "L6a0RCMc2UI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this updated code, I modified the forward method of the NuSALoss class to include an additional input parameter inputs, which represents the input sample to each layer (xl).\n",
        "\n",
        "Within the loop that iterates over the named parameters of the model, xl is now set as the inputs passed to the forward method. The NuSA term is computed by performing the necessary matrix multiplications and norms between column_space_basis and xl.\n",
        "\n",
        "By including inputs as an argument and using it in the NuSA term calculation, the code now incorporates the input sample for each layer into the loss function, as specified in the equation you provided.\n",
        "\n",
        "Once again, I apologize for the confusion caused by the incorrect information in my previous response."
      ],
      "metadata": {
        "id": "kfC0IHDP3JE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function with NuSA term\n",
        "class NuSALoss(nn.Module):\n",
        "    def __init__(self, lambda_value):\n",
        "        super(NuSALoss, self).__init__()\n",
        "        self.lambda_value = lambda_value\n",
        "\n",
        "    def forward(self, outputs, targets, model, inputs):\n",
        "        standard_loss = nn.CrossEntropyLoss()(outputs, targets)\n",
        "        nusa_term = 0.0\n",
        "\n",
        "        i = 0\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                weight = param.data\n",
        "                xl = inputs[i]  # Input sample to the layer\n",
        "                xl = xl.to(device)\n",
        "\n",
        "\n",
        "                i += 1\n",
        "                Q, _  = torch.qr(weight.t())\n",
        "                column_space_basis = Q.t()\n",
        "                column_space_basis = column_space_basis.to(device)\n",
        "                nusa_term += torch.norm(torch.matmul(torch.matmul(column_space_basis.t(),\n",
        "                                                                  column_space_basis), xl.t())) / xl.norm()\n",
        "\n",
        "        loss = standard_loss + self.lambda_value * nusa_term\n",
        "        return loss\n",
        "\n",
        "# Specify the lambda value for the tradeoff between the standard loss and the NuSA term\n",
        "lambda_value = 0.1  # You can change this value based on your needs\n",
        "\n",
        "# Create an instance of the loss function\n",
        "loss_function = NuSALoss(lambda_value)\n"
      ],
      "metadata": {
        "id": "RjT4lYUd3lAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criterion = nn.CrossEntropyLoss()\n",
        "def train(train_loader,network):\n",
        "\n",
        "    optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
        "    global loss_function\n",
        "    # new_train_loader = make_train_loader_from_number_class_we_want(number_of_known_classes)\n",
        "    for epoch in range(20):\n",
        "        print(epoch)\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass through the WideResNet model\n",
        "            with torch.no_grad():\n",
        "                features = model(images)\n",
        "\n",
        "            # Flatten the features\n",
        "            features = features.view(features.size(0), -1)\n",
        "            # Forward pass through the classifier\n",
        "            outputs,relue_x2,relue_x1 = network(features)\n",
        "            inputs = [features,relue_x1,relue_x2]\n",
        "            # Move input and target tensors to the same device\n",
        "            outputs = outputs.to(device)\n",
        "            loss = loss_function(outputs, labels,network,inputs)\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'loss: {loss}')\n",
        "\n",
        "    return network"
      ],
      "metadata": {
        "id": "tv99XWM94IgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the classifier's performance:\n",
        "`"
      ],
      "metadata": {
        "id": "csQDdFUL8jyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nusa_testing(data_loader, classifier, threshold):\n",
        "    outlier_indicator = []\n",
        "    outlier_class_labels = []\n",
        "    global model\n",
        "    classifier.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            # print(len(inputs))\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            features = model(inputs)\n",
        "\n",
        "            # Flatten the features\n",
        "            features = features.view(features.size(0), -1)\n",
        "\n",
        "\n",
        "            outputs,relue_x2,relu_x1 = classifier(features)  # Compute forward pass to get output for the sample\n",
        "            nusa = compute_nusa(classifier,[features,relu_x1,relue_x2])  # Compute NuSA for the sample\n",
        "\n",
        "            if nusa > threshold:\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                outlier_indicator.append(False)\n",
        "                outlier_class_labels.append(predicted.item())\n",
        "            else:\n",
        "                outlier_indicator.append(True)\n",
        "                outlier_class_labels.append(None)\n",
        "\n",
        "    return outlier_indicator, outlier_class_labels\n",
        "\n",
        "def compute_nusa(model,inputs):\n",
        "    nusa = 0.0\n",
        "    i = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            weight = param.data\n",
        "            xl = inputs[i]\n",
        "            xl = xl.to(device)\n",
        "            i += 1\n",
        "            # Reshape the weight tensor\n",
        "            Q,_ = torch.qr(weight.t())\n",
        "            column_space_basis = Q.t()\n",
        "            column_space_basis = column_space_basis.to(device)\n",
        "            nusa += torch.norm(torch.matmul(torch.matmul(column_space_basis.t(),\n",
        "                                                         column_space_basis), xl.t())) / xl.norm()\n",
        "\n",
        "    return nusa"
      ],
      "metadata": {
        "id": "1fAcMp6d9KeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def test(test_loader,network,list_of_acceptable_label,thershold=0.1):\n",
        "\n",
        "    outlier_indicator, outlier_class_labels = nusa_testing(test_loader,network,thershold)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for outlier_indi,outlier_labels,test in zip(outlier_indicator, outlier_class_labels,test_loader):\n",
        "\n",
        "        if test[1] in list_of_acceptable_label:\n",
        "          total += 1\n",
        "\n",
        "        if not outlier_indi:\n",
        "            if outlier_labels == test[1]:\n",
        "              correct += 1\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy}%\")\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "hAMTLTwB8kbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# test_res = []\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/data_maining_project/test_res_20.pkl\"\n",
        "\n",
        "# Write the content to the file\n",
        "# joblib.dump(test_res, file_path)\n",
        "\n",
        "# test_res = []"
      ],
      "metadata": {
        "id": "c3mxL98ipvOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an instance of the network for known 2\n",
        "network = SimpleNetwork(2)\n",
        "network = train(train_loader_2,network)\n"
      ],
      "metadata": {
        "id": "QhVPmDRsNLgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1],0.1)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "FzseEL-5l851"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = []"
      ],
      "metadata": {
        "id": "GTfBMXbwrfx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "sODu9nqd2Jdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an instance of the network for known 3\n",
        "network = SimpleNetwork(3)\n",
        "network = train(train_loader_3,network)\n",
        "\n"
      ],
      "metadata": {
        "id": "mgHewIPs2Pdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2],0.3)\n",
        "test_res.append(res)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "AGy5Sn_awOfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = [test_res[0] ,test_res[-1]]\n",
        "test_res"
      ],
      "metadata": {
        "id": "r40cmN5n3Ytk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "UGhJ6Jqq2Whe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 4\n",
        "network = SimpleNetwork(4)\n",
        "network = train(train_loader_4,network)\n"
      ],
      "metadata": {
        "id": "mOZsBlar2XFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3],0.4)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "UbA6RnuD8Hah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = [test_res[0],test_res[1],test_res[-1]]\n",
        "test_res"
      ],
      "metadata": {
        "id": "J5MjSfKG_gbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6yxAdDeQ_kg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "ChwrvDiO2fT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 5\n",
        "network = SimpleNetwork(5)\n",
        "network = train(train_loader_5,network)\n"
      ],
      "metadata": {
        "id": "P4c4z2GO2mAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3,4],0.1)\n",
        "test_res.append(res)\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "1-JEr2PiEcEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = [test_res[0],test_res[1],test_res[2],test_res[-1]]"
      ],
      "metadata": {
        "id": "ABC5egFmMeNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = joblib.load(\"/content/drive/MyDrive/data_maining_project/test_res_20.pkl\")"
      ],
      "metadata": {
        "id": "zxIXeYTnIL1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "fi4Dnkxc2vhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res"
      ],
      "metadata": {
        "id": "Sl4h3tBTuE6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 6\n",
        "network = SimpleNetwork(6)\n",
        "network = train(train_loader_6,network)\n",
        "\n"
      ],
      "metadata": {
        "id": "yfD463_H2wOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3,4,5],0)\n",
        "test_res.append(res)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "fznkHkK9uMOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res"
      ],
      "metadata": {
        "id": "paEfn1-750fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res = [test_res[0],test_res[1],test_res[2],test_res[3],test_res[4],test_res[5]]"
      ],
      "metadata": {
        "id": "DeOwAt3Y53VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "8t1B3_t_23JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 7\n",
        "network = SimpleNetwork(7)\n",
        "network = train(train_loader_7,network)\n",
        "\n"
      ],
      "metadata": {
        "id": "T5IxLikL24lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3,4,5,6],0.01)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "zIinnhGq6LOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hv-bQgg_PMjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res.append(res)\n",
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "f8BxB8V13APh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 8\n",
        "network = SimpleNetwork(8)\n",
        "network = train(train_loader_8,network)\n"
      ],
      "metadata": {
        "id": "nckzBZal3Ayt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3,4,5,6,7],0.3)\n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "id": "VfjzYygp7c_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res.append(res)\n"
      ],
      "metadata": {
        "id": "7Lh-5SkJTQMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "1bD-erDY3K2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 9\n",
        "network = SimpleNetwork(9)\n",
        "network = train(train_loader_9,network)\n"
      ],
      "metadata": {
        "id": "IcFWr8Jv3Lav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = test(test_loader,network,[0,1,2,3,4,5,6,7,8],1.2)\n",
        "\n",
        "print(res)\n"
      ],
      "metadata": {
        "id": "aC3xgF-W7JF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_res.append(res)\n"
      ],
      "metadata": {
        "id": "zD1FgvdvgXHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NOPmXTxWj_Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to the file\n",
        "joblib.dump(test_res, file_path)\n"
      ],
      "metadata": {
        "id": "JjS2sJBf3RDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/data_maining_project/test_res_20.pkl\"\n",
        "\n",
        "# Write the content to the file\n",
        "loaded_object = joblib.load(file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kJPmJyJe-IcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kuD5jVzMjT_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_object"
      ],
      "metadata": {
        "id": "GyuebwlPjTuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of labels for the x-axis\n",
        "labels = [i for i in range(2,10)]\n",
        "\n",
        "# Create the bar graph\n",
        "plt.bar(labels, loaded_object)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Bar Graph')\n",
        "\n",
        "# Display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4FQgXiG8_Ckd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "res_nsu = joblib.load('test_res_nsu.pkl')\n",
        "res_without_nsu = joblib.load('test_res_withouth_nsu.pkl')\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# List of labels for the x-axis\n",
        "labels = [i for i in range(2,10)]\n",
        "\n",
        "# Set the width of each bar\n",
        "bar_width = 0.35\n",
        "\n",
        "# Create the x-axis values\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Create the grouped bar graph\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - bar_width/2, res_nsu, bar_width, label='NuSA')\n",
        "rects2 = ax.bar(x + bar_width/2, res_without_nsu, bar_width, label='No NuSA')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Categories')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('Comparison two NuSA and No NuSA')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "# Display the graph\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LLnBogLJLLd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def nusa_testing_for_precission_recall(data_loader, classifier, threshold):\n",
        "    outlier_indicator = []\n",
        "    outlier_class_labels = []\n",
        "    global model\n",
        "    classifier.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            # print(len(inputs))\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            features = model(inputs)\n",
        "\n",
        "            # Flatten the features\n",
        "            features = features.view(features.size(0), -1)\n",
        "\n",
        "\n",
        "            outputs,relue_x2,relu_x1 = classifier(features)  # Compute forward pass to get output for the sample\n",
        "            nusa = compute_nusa(classifier,[features,relu_x1,relue_x2])  # Compute NuSA for the sample\n",
        "            print(nusa)\n",
        "            outputs = outputs[0].numpy()\n",
        "            outputs = outputs.tolist()\n",
        "            outputs.append(0)\n",
        "            # print(outputs)\n",
        "            if nusa > threshold:\n",
        "                outlier_indicator.append(False)\n",
        "                outlier_class_labels.append(outputs)\n",
        "            else:\n",
        "                outlier_indicator.append(True)\n",
        "                outlier_class_labels.append(np.array([0,0,0,0,0,1]))\n",
        "\n",
        "    return outlier_indicator, outlier_class_labels\n",
        "\n",
        "def compute_nusa(model,inputs):\n",
        "    nusa = 0.0\n",
        "    i = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            weight = param.data\n",
        "            xl = inputs[i]\n",
        "            xl = xl.to(device)\n",
        "            i += 1\n",
        "            # Reshape the weight tensor\n",
        "            # weight_reshaped = weight.permute(1, 0, 2, 3).reshape(weight.size(1), -1)\n",
        "\n",
        "            # Q, _  = torch.qr(weight_reshaped.t())\n",
        "            Q,_ = torch.qr(weight.t())\n",
        "            column_space_basis = Q.t()\n",
        "\n",
        "            # column_space_basis = column_space_basis.to(device)\n",
        "            # nusa += torch.norm(torch.matmul(torch.matmul(column_space_basis.t(), column_space_basis), x.t())) / x.norm()\n",
        "\n",
        "            column_space_basis = column_space_basis.to(device)\n",
        "            nusa += torch.norm(torch.matmul(torch.matmul(column_space_basis.t(), column_space_basis), xl.t())) / xl.norm()\n",
        "\n",
        "    return nusa"
      ],
      "metadata": {
        "id": "4EPzc53PHlcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_for_precission_recall(test_loader,network,list_of_acceptable_label):\n",
        "\n",
        "    outlier_indicator, outlier_class_labels = nusa_testing_for_precission_recall(test_loader,network,1.8)\n",
        "    print(outlier_indicator)\n",
        "\n",
        "    true_label = []\n",
        "    predict_label = []\n",
        "\n",
        "    for outlier_indi,outlier_labels,test in zip(outlier_indicator, outlier_class_labels,test_loader):\n",
        "\n",
        "        if test[1] in list_of_acceptable_label :\n",
        "          true_label.append(test[1])\n",
        "        else :\n",
        "          true_label.append(5)\n",
        "\n",
        "        if not outlier_indi:\n",
        "            predict_label.append(outlier_labels)\n",
        "        else:\n",
        "             predict_label.append(outlier_labels)\n",
        "\n",
        "\n",
        "    return true_label,predict_label\n"
      ],
      "metadata": {
        "id": "taDLMzSoDgJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the network for known 5\n",
        "# network = SimpleNetwork(5)\n",
        "# network = train(train_loader_5,network)\n",
        "true_labels,predict_labels = test_for_precission_recall(test_loader,network,[0,1,2,3,4])\n",
        "\n"
      ],
      "metadata": {
        "id": "epNmmlFjDScI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6n3bLXmoQOqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Assuming you have the true labels and predicted probabilities for each class\n",
        "true_labels = np.array(true_labels)  # True labels for the samples\n",
        "predicted_probs = np.array(predict_labels)  # Predicted probabilities for each class (shape: 5x5)\n",
        "# print(predict_labels)\n",
        "# Plot Precispredict_labelsion-Recall curves for each class\n",
        "plt.figure()\n",
        "\n",
        "for class_label in range(6):\n",
        "    binary_true_labels = [1 if label == class_label else 0 for label in true_labels]\n",
        "    prob_scores = predicted_probs[:, class_label]\n",
        "    precision, recall, _ = precision_recall_curve(binary_true_labels, prob_scores)\n",
        "    average_precision = average_precision_score(binary_true_labels, prob_scores)\n",
        "    plt.plot(recall, precision, label=f'Class {class_label} (AP = {average_precision:.2f})')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve for (Five known Classes)')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YVKF5ViABam_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}